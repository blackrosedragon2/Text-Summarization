{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextSummarization",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackrosedragon2/Text-Summarization/blob/master/TextSummarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEvQFi0wa1fA",
        "colab_type": "code",
        "outputId": "8f6c4473-590b-499d-91bc-7f89babff0f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!pip install tqdm\n",
        "!pip install torchsummaryx\n",
        "!pip install nltk\n",
        "!pip install pyspellchecker\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: torchsummaryx in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torchsummaryx) (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchsummaryx) (1.17.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchsummaryx) (1.3.0+cu100)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torchsummaryx) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torchsummaryx) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->torchsummaryx) (1.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (0.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqrMHmThPzJb",
        "colab_type": "code",
        "outputId": "cdb96c87-6a68-4cae-a2db-94800fe64ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Reading data onto zipfile object ZF\n",
        "from google.colab import drive\n",
        "import os \n",
        "import zipfile\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = '/content/gdrive/My Drive/data/'  \n",
        "zf=zipfile.ZipFile(root_path+\"cnn_stories.zip\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9aAAGcDdq2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from spellchecker import SpellChecker\n",
        "import nltk\n",
        "#nltk.download()\n",
        "class preprocess:\n",
        "    #Accepts a string and performs string operations on it\n",
        "    def seperate(self,para):#1\n",
        "        # find @highlight, add length and split story and summary, then decode to utf-8 format, use split tokenizer and seperate the 4 lines , split the \\n parts and return the list\n",
        "        story=para[:para.find('@highlight')]\n",
        "        summary=[i.splitlines()[2] for i in (para[para.find('@highlight')+len('@highlight'):]).split('@highlight')]\n",
        "        return story,summary    \n",
        "        #returns (string,list)\n",
        "    \n",
        "    def spell_check(self,para):#2\n",
        "        #corrects spellings(may not be used for us) + takes much longer to correct spellings (5+ minutes)\n",
        "        spell = SpellChecker()\n",
        "        para=para.split(' ')\n",
        "        correctpara=[]\n",
        "        for word in para:\n",
        "            correctpara.append(spell.correction(word))\n",
        "        return ' '.join(correctpara)\n",
        "\n",
        "    def remove_apostrophes(self,para):#3\n",
        "        return re.sub(\"(?<=[a-z])'(?=[a-z])\", \"\", para)\n",
        "\n",
        "    def remove_parentheses(self,para):#4\n",
        "        #removes anything inside parentheses\n",
        "        return re.sub(r'\\([^)]*\\)', '', para)\n",
        "\n",
        "    def remove_sp(self,para):#5\n",
        "        #removes special symbols\n",
        "        return re.sub('[^A-Za-z0-9]+', ' ', para)   #note: add exception for words like U.N. \n",
        "\n",
        "    def remove_short(self,para):#6\n",
        "        #removes words that are <3 in length\n",
        "        para=para.split(' ')\n",
        "        longpara=[]\n",
        "        for word in para:\n",
        "            if len(word) >= 3:\n",
        "                longpara.append(word)\n",
        "        return ' '.join(longpara)\n",
        "\n",
        "    def add_tags(self,para):#7\n",
        "        #add start and end tags \n",
        "        para=\"<start>\"+para+\"<end>\"\n",
        "        return para\n",
        "\n",
        "    def tokenize(self,para):#8\n",
        "        tokenlist = nltk.word_tokenize(para)\n",
        "        return tokenlist\n",
        "\n",
        "    def apply_all(self,para):#9\n",
        "        #applies 1,3,4,5,6 functions, may need reordering \n",
        "        p=preprocess()\n",
        "\n",
        "        story,summary=p.seperate(para.decode(\"utf-8\"))\n",
        "\n",
        "        #story=p.spell_check(story)\n",
        "        #summary=p.spell_check(summary)\n",
        "\n",
        "        story=p.remove_apostrophes(story)\n",
        "        summary=[p.remove_apostrophes(i) for i in summary] \n",
        "\n",
        "        story=p.remove_parentheses(story)\n",
        "        summary=[p.remove_parentheses(i) for i in summary]\n",
        "\n",
        "        story=p.remove_sp(story)\n",
        "        summary=[p.remove_sp(i) for i in summary]\n",
        "\n",
        "        story=p.remove_short(story)# may not be needed\n",
        "        summary=[p.remove_short(i) for i in summary]\n",
        "\n",
        "        story=p.tokenize(story)\n",
        "        summary=[p.tokenize(i) for i in summary]\n",
        "\n",
        "        return story,summary\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRFIPzWhP-Km",
        "colab_type": "code",
        "outputId": "cbb53804-42a4-41bc-adb1-4df41f77e558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "#Read content of all files onto x (takes approximatly 13 minutes for both modes)\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_data(preproc=0):\n",
        "    i=1\n",
        "    if preproc==1:\n",
        "        stories=[]\n",
        "        story=[]\n",
        "        summaries=[]\n",
        "        summary=[]\n",
        "        p=preprocess()\n",
        "        with tqdm(total=92600) as pbar:\n",
        "            while(True):\n",
        "                #Reads zip file until eof exception occurs\n",
        "                i=i+1\n",
        "                try:\n",
        "                    story,summary=p.apply_all(zf.open(zf.namelist()[i]).read())\n",
        "                    stories.append(story)\n",
        "                    summaries.append(summary)\n",
        "                except Exception as E:\n",
        "                    break\n",
        "                pbar.update(1)\n",
        "        return stories,summaries\n",
        "    else:\n",
        "        x=[]\n",
        "        with tqdm(total=92600) as pbar:\n",
        "            while(True):\n",
        "                #Reads zip file until eof exception occurs\n",
        "                i=i+1\n",
        "                try:\n",
        "                    x.append(zf.open(zf.namelist()[i]).read())\n",
        "                except Exception as E:\n",
        "                    break\n",
        "                pbar.update(1)\n",
        "        return x\n",
        "\n",
        "story,summary=get_data(1) \n",
        "for j,i in enumerate(summary):\n",
        "    print(i)\n",
        "    if j>10:\n",
        "        break\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 92579/92600 [22:12<00:00, 69.49it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[['Syrian', 'official', 'Obama', 'climbed', 'the', 'top', 'the', 'tree', 'doesnt', 'know', 'how', 'get', 'down'], ['Obama', 'sends', 'letter', 'the', 'heads', 'the', 'House', 'and', 'Senate'], ['Obama', 'seek', 'congressional', 'approval', 'military', 'action', 'against', 'Syria'], ['Aim', 'determine', 'whether', 'were', 'used', 'not', 'whom', 'says', 'spokesman']]\n",
            "[['Usain', 'Bolt', 'wins', 'third', 'gold', 'world', 'championship'], ['Anchors', 'Jamaica', '4x100m', 'relay', 'victory'], ['Eighth', 'gold', 'the', 'championships', 'for', 'Bolt'], ['Jamaica', 'double', 'womens', '4x100m', 'relay']]\n",
            "[['The', 'employee', 'agencys', 'Kansas', 'City', 'office', 'among', 'hundreds', 'virtual', 'workers'], ['The', 'employees', 'travel', 'and', 'from', 'the', 'mainland', 'last', 'year', 'cost', 'more', 'than', '000'], ['The', 'telecommuting', 'program', 'like', 'all', 'GSA', 'practices', 'under', 'review']]\n",
            "[['NEW', 'Canadian', 'doctor', 'says', 'she', 'was', 'part', 'team', 'examining', 'Harry', 'Burkhart', '2010'], ['NEW', 'Diagnosis', 'autism', 'severe', 'anxiety', 'post', 'traumatic', 'stress', 'disorder', 'and', 'depression'], ['Burkhart', 'also', 'suspected', 'German', 'arson', 'probe', 'officials', 'say'], ['Prosecutors', 'believe', 'the', 'German', 'national', 'set', 'string', 'fires', 'Los', 'Angeles']]\n",
            "[['Another', 'arrest', 'made', 'gang', 'rape', 'outside', 'California', 'school'], ['Investigators', 'say', 'people', 'took', 'part', 'stood', 'and', 'watched', 'the', 'assault'], ['Four', 'suspects', 'appeared', 'court', 'Thursday', 'three', 'wore', 'bulletproof', 'vests']]\n",
            "[['Humanitarian', 'groups', 'expect', '000', 'refugees', 'one', 'camp', 'official', 'says'], ['Others', 'have', 'fled', 'across', 'the', 'border', 'camps', 'Liberia', 'says'], ['This', 'follows', 'attacks', 'that', 'killed', 'peacekeepers', 'and', 'civilians']]\n",
            "[['NEW', 'groups', 'announce', 'legal', 'challenge', 'Phoenix'], ['American', 'Civil', 'Liberties', 'Union', 'ACLU', 'Arizona', 'National', 'Immigration', 'Law', 'Center', 'slam', 'law'], ['Mexican', 'American', 'Legal', 'Defense', 'and', 'Educational', 'Fund', 'also', 'objects'], ['They', 'say', 'law', 'encourages', 'racial', 'profiling', 'but', 'supporters', 'say', 'doesnt', 'involve', 'any', 'illegal', 'acts']]\n",
            "[['Labor', 'Day', 'the', 'unofficial', 'end', 'summer', 'and', 'the', 'unofficial', 'start', 'campaign', 'season'], ['much', 'billion', 'could', 'spent', 'advertising', 'for', 'this', 'midterm', 'election'], ['Here', 'are', 'five', 'must', 'follow', 'races', 'for', 'these', 'midterms']]\n",
            "[['NEW', 'Autopsy', 'indicates', 'had', 'been', 'dead', 'for', 'hours', 'before', 'police', 'arrived'], ['YouTube', 'video', 'appears', 'show', 'the', 'activist', 'bound', 'and', 'blindfolded'], ['The', 'activist', 'and', 'freelance', 'journalist', 'was', 'from', 'the', 'Lombardy', 'region', 'northern', 'Italy']]\n",
            "[['The', 'radio', 'personality', 'was', 'taken', 'hospital', 'Sunday'], ['Spokesman', 'for', 'hospital', 'says', 'Casey', 'Kasem', 'being', 'treated', 'for', 'wounds', 'blood', 'pressure', 'issues'], ['had', 'been', 'friends', 'home', 'Washington', 'state', 'after', 'his', 'wife', 'took', 'him', 'there'], ['She', 'has', 'been', 'feuding', 'with', 'three', 'stepchildren', 'over', 'the', 'radio', 'icons', 'care']]\n",
            "[['Hawaiian', 'Airlines', 'again', 'lands', 'time', 'performance'], ['The', 'Airline', 'Quality', 'Rankings', 'Report', 'looks', 'the', 'largest', 'airlines'], ['ExpressJet', 'and', 'American', 'Airlines', 'had', 'the', 'worst', 'time', 'performance'], ['Virgin', 'America', 'had', 'the', 'best', 'baggage', 'handling', 'Southwest', 'had', 'lowest', 'complaint', 'rate']]\n",
            "[['The', 'new', 'cardinals', 'will', 'installed', 'February'], ['They', 'come', 'from', 'countries', 'such', 'Myanmar', 'and', 'Tonga'], ['Americans', 'made', 'the', 'list', 'this', 'time', 'the', 'previous', 'time', 'Francis', 'papacy']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK5-djtlMoZ_",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://pytorch.org/tutorials/_images/encoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XalfZdPbhJ1M",
        "colab_type": "code",
        "outputId": "f00cbeed-87ea-49fd-eb7b-6e93c322aa02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "%xmode Plain\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchsummaryX import summary\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "class GRU_Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, drop=0.2):\n",
        "        super(GRU_Encoder, self).__init__()\n",
        "        #GRU with dropout,fc layer, relu layer\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, dropout=drop, bidirectional =True) \n",
        "        #batch first will create dims such that dimensions=(batch,dim1,dim2...)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data      \n",
        "         #grabs any parameter of the model and uses it to instantiate (through .data.new) a new tensor on the same device\n",
        "        hidden = weight.new(2, batch_size, self.hidden_size).zero_().to(device)\n",
        "        #ints a hidden vector shape( n_layer,batch_size,hidden_size) to zero , nlayer= 2 because bidirectional \n",
        "        return hidden\n",
        "\n",
        "    def forward(self, x, h=0):# x dims=()\n",
        "        if h==0:\n",
        "            h=self.init_hidden(16)\n",
        "\n",
        "        embedded = self.embedding(x).view(x.shape[0],-1,self.hidden_size)\n",
        "        out=embedded\n",
        "        out, h = self.gru(out, h)  \n",
        "        print(\"X {},OUTPUT {},HIDDEN {}\".format(x.shape,out.shape,h.shape))\n",
        "\n",
        "        return out, h  #(output of encoder(give to-> attention mechanism ), next hidden state)\n",
        "\n",
        "#input trensor dims must be (i/p dim,timesteps,batchsize)\n",
        "gruEncoder_model=GRU_Encoder(input_size=10, hidden_size=128, output_size=10)\n",
        "inputs = torch.zeros((16,10, 10), dtype=torch.long) # (batch_size, outputdim, inputdim)\n",
        "inputs=inputs.cuda()\n",
        "gruEncoder_model.cuda()\n",
        "summary(gruEncoder_model,inputs)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception reporting mode: Plain\n",
            "X torch.Size([16, 10, 10]),OUTPUT torch.Size([16, 100, 256]),HIDDEN torch.Size([2, 16, 128])\n",
            "==============================================================\n",
            "            Kernel Shape       Output Shape  Params  Mult-Adds\n",
            "Layer                                                         \n",
            "0_embedding    [128, 10]  [16, 10, 10, 128]    1280       1280\n",
            "1_gru                  -     [16, 100, 256]  198144     196608\n",
            "--------------------------------------------------------------\n",
            "                      Totals\n",
            "Total params          199424\n",
            "Trainable params      199424\n",
            "Non-trainable params       0\n",
            "Mult-Adds             197888\n",
            "==============================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_embedding</th>\n",
              "      <td>[128, 10]</td>\n",
              "      <td>[16, 10, 10, 128]</td>\n",
              "      <td>1280</td>\n",
              "      <td>1280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_gru</th>\n",
              "      <td>-</td>\n",
              "      <td>[16, 100, 256]</td>\n",
              "      <td>198144</td>\n",
              "      <td>196608</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Kernel Shape       Output Shape  Params  Mult-Adds\n",
              "Layer                                                         \n",
              "0_embedding    [128, 10]  [16, 10, 10, 128]    1280       1280\n",
              "1_gru                  -     [16, 100, 256]  198144     196608"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ09Hx0rMdFA",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://pytorch.org/tutorials/_images/attention-decoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mjZkW0ubJDrm",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=15):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, encoder_outputs,hidden=1):\n",
        "        if hidden==1:\n",
        "            hidden=self.initHidden()\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) #calculate a set of attention weight\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0)) #bmm atn_weight, encoder_op\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1) #concat embedded i/p vector and attn applied\n",
        "        output = self.attn_combine(output).unsqueeze(0) #Apply linear layer to concat vector\n",
        "\n",
        "        output = F.relu(output) #apply relu\n",
        "        output, hidden = self.gru(output, hidden) #apply gru to hidden and transformed attention vector\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)#softmax for output\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZYC0Tzy4JDRH",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0qfWLjEEJBgj",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}